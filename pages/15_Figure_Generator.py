"""
ë…¼ë¬¸ìš© Figure ìƒì„± í˜ì´ì§€
Publication-quality figures for PSYCHE framework paper

ëª¨ë“  í°íŠ¸ëŠ” Helveticaë¡œ í†µì¼
All fonts unified to Helvetica
"""

import streamlit as st
import pandas as pd
import numpy as np
from firebase_config import get_firebase_ref
from expert_validation_utils import sanitize_firebase_key
import matplotlib.pyplot as plt
import matplotlib
from matplotlib import rcParams
from scipy import stats
import seaborn as sns
import io

# ================================
# Configuration
# ================================
st.set_page_config(
    page_title="Publication Figures",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Helvetica í°íŠ¸ ì„¤ì •
rcParams['font.family'] = 'Helvetica'
rcParams['axes.unicode_minus'] = False

# Seaborn ìŠ¤íƒ€ì¼
sns.set_style("ticks")

# ================================
# PRESET - Experiment Numbers
# ================================
EXPERIMENT_NUMBERS = [
    # 6201 MDD
    (6201, 3111), (6201, 3117),  # gptsmaller
    (6201, 1121), (6201, 1123),  # gptlarge
    (6201, 3134), (6201, 3138),  # claudesmaller
    (6201, 1143), (6201, 1145),  # claudelarge
    # 6202 BD
    (6202, 3211), (6202, 3212),  # gptsmaller
    (6202, 1221), (6202, 1222),  # gptlarge
    (6202, 3231), (6202, 3234),  # claudesmaller
    (6202, 1241), (6202, 1242),  # claudelarge
    # 6206 OCD
    (6206, 3611), (6206, 3612),  # gptsmaller
    (6206, 1621), (6206, 1622),  # gptlarge
    (6206, 3631), (6206, 3632),  # claudesmaller
    (6206, 1641), (6206, 1642),  # claudelarge
]

VALIDATORS = ["ì´ê°•í† ", "ê¹€íƒœí™˜", "ê¹€ê´‘í˜„", "ê¹€ì£¼ì˜¤", "í—ˆìœ¨", "ì¥ì¬ìš©"]

VALIDATOR_INITIALS = {
    "ì´ê°•í† ": "K.T. Lee",
    "ê¹€íƒœí™˜": "T.H. Kim",
    "ê¹€ê´‘í˜„": "K.H. Kim",
    "ê¹€ì£¼ì˜¤": "J.O. Kim",
    "í—ˆìœ¨": "Y. Heo",
    "ì¥ì¬ìš©": "J.Y. Jang"
}

DISORDER_MAP = {6201: "mdd", 6202: "bd", 6206: "ocd"}
DISORDER_NAMES = {
    "mdd": "Major Depressive Disorder",
    "bd": "Bipolar Disorder",
    "ocd": "Obsessive-Compulsive Disorder"
}

MODEL_BY_EXP = {
    3111: 'gptsmaller', 3117: 'gptsmaller',
    1121: 'gptlarge', 1123: 'gptlarge',
    3134: 'claudesmaller', 3138: 'claudesmaller',
    1143: 'claudelarge', 1145: 'claudelarge',
    3211: 'gptsmaller', 3212: 'gptsmaller',
    1221: 'gptlarge', 1222: 'gptlarge',
    3231: 'claudesmaller', 3234: 'claudesmaller',
    1241: 'claudelarge', 1242: 'claudelarge',
    3611: 'gptsmaller', 3612: 'gptsmaller',
    1621: 'gptlarge', 1622: 'gptlarge',
    3631: 'claudesmaller', 3632: 'claudesmaller',
    1641: 'claudelarge', 1642: 'claudelarge',
}

# ìƒ‰ìƒ ë° ë§ˆì»¤ ë§¤í•‘ (ë…¼ë¬¸ìš©)
COLOR_MAP = {
    "gptsmaller": "#2ecc71",     # ì´ˆë¡ìƒ‰
    "gptlarge": "#27ae60",       # ì§„í•œ ì´ˆë¡ìƒ‰
    "claudesmaller": "#e67e22",  # ì£¼í™©ìƒ‰
    "claudelarge": "#d35400"     # ì§„í•œ ì£¼í™©ìƒ‰
}

MARKER_MAP = {
    "gptsmaller": {"marker": "o", "size": 300},
    "gptlarge": {"marker": "*", "size": 600},
    "claudesmaller": {"marker": "o", "size": 300},
    "claudelarge": {"marker": "*", "size": 600}
}

LABEL_MAP = {
    "gptsmaller": "GPT-Smaller",
    "gptlarge": "GPT-Large",
    "claudesmaller": "Claude-Smaller",
    "claudelarge": "Claude-Large"
}

def get_model_from_exp(exp_num):
    """Identify model from experiment number."""
    return MODEL_BY_EXP.get(exp_num, 'unknown')

# ================================
# Data Loading Functions
# ================================
def load_expert_scores(root_data):
    """Load expert scores for all validators and experiments."""
    expert_data = {}
    for validator in VALIDATORS:
        sanitized_name = sanitize_firebase_key(validator)
        validator_scores = {}
        for client_num, exp_num in EXPERIMENT_NUMBERS:
            key = f"expert_{sanitized_name}_{client_num}_{exp_num}"
            data = (root_data or {}).get(key, {}) or {}
            if 'expert_score' in data:
                validator_scores[(client_num, exp_num)] = data['expert_score']
            elif 'psyche_score' in data:
                validator_scores[(client_num, exp_num)] = data['psyche_score']
            else:
                validator_scores[(client_num, exp_num)] = None
        expert_data[validator] = validator_scores
    return expert_data

def load_psyche_scores(root_data):
    """Load automated PSYCHE scores."""
    psyche_data = {}
    for client_num, exp_num in EXPERIMENT_NUMBERS:
        value = None
        target_prefix = f"clients_{client_num}_psyche_"
        target_suffix = f"_{exp_num}"
        for key, data in (root_data or {}).items():
            if not key.startswith(target_prefix):
                continue
            if not key.endswith(target_suffix):
                continue
            record = data or {}
            if 'psyche_score' in record:
                value = record['psyche_score']
                break
        psyche_data[(client_num, exp_num)] = value
    return psyche_data

def calculate_average_expert_scores(expert_data):
    """Calculate average expert scores across validators."""
    avg_scores = {}
    for exp in EXPERIMENT_NUMBERS:
        scores = [expert_data[v].get(exp) for v in VALIDATORS if expert_data[v].get(exp) is not None]
        avg_scores[exp] = np.mean(scores) if scores else None
    return avg_scores

# ================================
# Figure 1: PSYCHE-Expert Correlation
# ================================
def create_correlation_plot_average(psyche_scores, avg_expert_scores, figsize=(8, 8)):
    """Figure 1-1: Average expert score correlation plot."""
    fig, ax = plt.subplots(figsize=figsize)
    
    # ë°ì´í„° ì¤€ë¹„
    data_by_model = {model: [] for model in COLOR_MAP.keys()}
    
    for exp in EXPERIMENT_NUMBERS:
        psyche = psyche_scores.get(exp)
        expert = avg_expert_scores.get(exp)
        if psyche is not None and expert is not None:
            model = get_model_from_exp(exp[1])
            if model in data_by_model:
                data_by_model[model].append((psyche, expert))
    
    # Scatter plot
    all_x, all_y = [], []
    for model, points in data_by_model.items():
        if points:
            x, y = zip(*points)
            all_x.extend(x)
            all_y.extend(y)
            ax.scatter(x, y, 
                      c=COLOR_MAP[model],
                      marker=MARKER_MAP[model]["marker"],
                      s=MARKER_MAP[model]["size"],
                      label=LABEL_MAP[model],
                      alpha=0.7)
    
    # íšŒê·€ì„ 
    if len(all_x) >= 2:
        z = np.polyfit(all_x, all_y, 1)
        p = np.poly1d(z)
        x_line = np.linspace(min(all_x), max(all_x), 100)
        ax.plot(x_line, p(x_line), '#3498db', linestyle='-', linewidth=2)
        
        # Correlation
        correlation, p_value = stats.pearsonr(all_x, all_y)
        p_text = 'p < 0.0001' if p_value < 0.0001 else f'p = {p_value:.4f}'
        ax.text(0.3, 0.10, f'r = {correlation:.4f}, {p_text}',
               transform=ax.transAxes, fontsize=32, family='Helvetica')
    
    # ìŠ¤íƒ€ì¼ë§
    ax.set_title('PSYCHE SCORE vs. Expert score', fontsize=36, pad=20, family='Helvetica')
    ax.set_xlabel('PSYCHE SCORE', fontsize=36, family='Helvetica')
    ax.set_ylabel('Expert score', fontsize=36, family='Helvetica')
    ax.tick_params(labelsize=32)
    ax.legend(loc='upper left', prop={'size': 22, 'weight': 'bold', 'family': 'Helvetica'})
    
    # í…Œë‘ë¦¬
    for spine in ax.spines.values():
        spine.set_color('black')
        spine.set_linewidth(2)
    
    plt.tight_layout()
    return fig

def create_correlation_plot_by_validator(psyche_scores, expert_data):
    """Figure 1-2: Individual validator correlation plots."""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    for idx, validator in enumerate(VALIDATORS):
        ax = axes[idx]
        
        # ë°ì´í„° ìˆ˜ì§‘
        validator_x, validator_y = [], []
        data_by_model = {model: [] for model in COLOR_MAP.keys()}
        
        for exp in EXPERIMENT_NUMBERS:
            psyche = psyche_scores.get(exp)
            expert = expert_data[validator].get(exp)
            if psyche is not None and expert is not None:
                validator_x.append(psyche)
                validator_y.append(expert)
                model = get_model_from_exp(exp[1])
                if model in data_by_model:
                    data_by_model[model].append((psyche, expert))
        
        # Scatter plot
        for model, points in data_by_model.items():
            if points:
                x, y = zip(*points)
                ax.scatter(x, y,
                          c=COLOR_MAP[model],
                          marker=MARKER_MAP[model]["marker"],
                          s=150,
                          alpha=0.7)
        
        # íšŒê·€ì„  ë° correlation
        if len(validator_x) >= 2:
            z = np.polyfit(validator_x, validator_y, 1)
            p = np.poly1d(z)
            x_line = np.linspace(min(validator_x), max(validator_x), 100)
            ax.plot(x_line, p(x_line), '#3498db', linestyle='-', linewidth=2)
            
            correlation, p_value = stats.pearsonr(validator_x, validator_y)
            p_text = 'p < 0.0001' if p_value < 0.0001 else f'p = {p_value:.4f}'
            ax.text(0.05, 0.95, f'r = {correlation:.3f}\n{p_text}\nn = {len(validator_x)}',
                   transform=ax.transAxes, fontsize=14, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                   family='Helvetica')
        
        # ìŠ¤íƒ€ì¼ë§
        ax.set_title(VALIDATOR_INITIALS[validator], fontsize=18, fontweight='bold', family='Helvetica')
        ax.set_xlabel('PSYCHE SCORE', fontsize=14, family='Helvetica')
        ax.set_ylabel('Expert score', fontsize=14, family='Helvetica')
        ax.tick_params(labelsize=12)
        ax.grid(True, alpha=0.3)
        
        for spine in ax.spines.values():
            spine.set_color('black')
            spine.set_linewidth(1)
    
    plt.tight_layout()
    return fig

def create_correlation_plot_by_disorder(psyche_scores, avg_expert_scores):
    """Figure 1-3: Disorder-specific correlation plots."""
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    for idx, (disorder_code, disorder_name) in enumerate([(6201, "MDD"), (6202, "BD"), (6206, "OCD")]):
        ax = axes[idx]
        
        # í•´ë‹¹ disorder ë°ì´í„°ë§Œ í•„í„°ë§
        data_by_model = {model: [] for model in COLOR_MAP.keys()}
        all_x, all_y = [], []
        
        for exp in EXPERIMENT_NUMBERS:
            if exp[0] != disorder_code:
                continue
            psyche = psyche_scores.get(exp)
            expert = avg_expert_scores.get(exp)
            if psyche is not None and expert is not None:
                all_x.append(psyche)
                all_y.append(expert)
                model = get_model_from_exp(exp[1])
                if model in data_by_model:
                    data_by_model[model].append((psyche, expert))
        
        # Scatter plot
        for model, points in data_by_model.items():
            if points:
                x, y = zip(*points)
                ax.scatter(x, y,
                          c=COLOR_MAP[model],
                          marker=MARKER_MAP[model]["marker"],
                          s=200,
                          alpha=0.7)
        
        # íšŒê·€ì„ 
        if len(all_x) >= 2:
            z = np.polyfit(all_x, all_y, 1)
            p = np.poly1d(z)
            x_line = np.linspace(min(all_x), max(all_x), 100)
            ax.plot(x_line, p(x_line), '#3498db', linestyle='-', linewidth=2)
            
            correlation, p_value = stats.pearsonr(all_x, all_y)
            p_text = 'p < 0.0001' if p_value < 0.0001 else f'p = {p_value:.4f}'
            ax.text(0.05, 0.95, f'r = {correlation:.4f}\n{p_text}',
                   transform=ax.transAxes, fontsize=14, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                   family='Helvetica')
        
        # ìŠ¤íƒ€ì¼ë§
        ax.set_title(DISORDER_NAMES[DISORDER_MAP[disorder_code]], fontsize=18, fontweight='bold', family='Helvetica')
        ax.set_xlabel('PSYCHE SCORE', fontsize=14, family='Helvetica')
        ax.set_ylabel('Expert score', fontsize=14, family='Helvetica')
        ax.tick_params(labelsize=12)
        ax.grid(True, alpha=0.3)
        
        for spine in ax.spines.values():
            spine.set_color('black')
            spine.set_linewidth(1)
    
    plt.tight_layout()
    return fig

# ================================
# Figure 2: Weight-Correlation Analysis
# ================================
def load_element_scores(root_data):
    """Load element-level scores for weight analysis."""
    element_scores = {}
    
    for client_num, exp_num in EXPERIMENT_NUMBERS:
        # Load PSYCHE evaluation data
        target_prefix = f"clients_{client_num}_psyche_"
        target_suffix = f"_{exp_num}"
        
        for key, data in (root_data or {}).items():
            if not key.startswith(target_prefix):
                continue
            if not key.endswith(target_suffix):
                continue
            
            record = data or {}
            if 'elements' in record:
                element_scores[(client_num, exp_num)] = record['elements']
                break
    
    return element_scores

def calculate_weighted_correlation_from_elements(element_scores_psyche, element_scores_expert, 
                                                  weight_impulsivity, weight_behavior, weight_subjective=1):
    """
    Elementë³„ ê°€ì¤‘ì¹˜ë¥¼ ë³€ê²½í•˜ì—¬ correlation ì¬ê³„ì‚°
    
    Parameters:
    - weight_impulsivity: Impulsivity category weight (default: 5)
    - weight_behavior: Behavior category weight (default: 2)
    - weight_subjective: Subjective category weight (fixed: 1)
    """
    from evaluator import PSYCHE_RUBRIC
    
    # Categoryë³„ element ë¶„ë¥˜
    impulsivity_elements = [k for k, v in PSYCHE_RUBRIC.items() if v.get('type') == 'impulsivity']
    behavior_elements = [k for k, v in PSYCHE_RUBRIC.items() if v.get('type') == 'behavior']
    subjective_elements = [k for k, v in PSYCHE_RUBRIC.items() if v.get('type') in ['g-eval', 'binary'] and v.get('weight') == 1]
    
    weighted_psyche_scores = []
    weighted_expert_scores = []
    
    for exp in EXPERIMENT_NUMBERS:
        psyche_elements = element_scores_psyche.get(exp, {})
        expert_elements = element_scores_expert.get(exp, {})
        
        if not psyche_elements or not expert_elements:
            continue
        
        psyche_total = 0
        expert_total = 0
        
        # Calculate weighted scores
        for element, rubric_info in PSYCHE_RUBRIC.items():
            if element not in psyche_elements or element not in expert_elements:
                continue
            
            psyche_elem = psyche_elements[element]
            expert_elem = expert_elements[element]
            
            # Get scores (0-1 range)
            psyche_score = psyche_elem.get('score', 0) if isinstance(psyche_elem, dict) else 0
            expert_score = expert_elem.get('score', 0) if isinstance(expert_elem, dict) else 0
            
            # Apply weights
            if element in impulsivity_elements:
                weight = weight_impulsivity
            elif element in behavior_elements:
                weight = weight_behavior
            elif element in subjective_elements:
                weight = weight_subjective
            else:
                weight = rubric_info.get('weight', 1)
            
            psyche_total += psyche_score * weight
            expert_total += expert_score * weight
        
        weighted_psyche_scores.append(psyche_total)
        weighted_expert_scores.append(expert_total)
    
    # Calculate correlation
    if len(weighted_psyche_scores) >= 2:
        correlation, _ = stats.pearsonr(weighted_psyche_scores, weighted_expert_scores)
        return correlation
    return None

def create_weight_correlation_heatmaps(element_scores_psyche, element_scores_expert):
    """Figure 2: Weight-correlation analysis heatmaps."""
    weight_range = range(1, 11)  # 1-10
    
    # Heatmap 1: Equal weights (PSYCHEì™€ Expert ëª¨ë‘ ê°€ì¤‘ì¹˜ ë³€ê²½)
    correlation_equal = np.zeros((10, 10))
    for i, w_imp in enumerate(weight_range):
        for j, w_beh in enumerate(weight_range):
            corr = calculate_weighted_correlation_from_elements(
                element_scores_psyche, element_scores_expert, w_imp, w_beh
            )
            correlation_equal[9-i, j] = corr if corr is not None else 0  # yì¶• ë°˜ì „ (top=10, bottom=1)
    
    # Heatmap 2: Fixed expert weights at (5, 2, 1)
    # ExpertëŠ” (5,2,1) ê³ ì •, PSYCHEë§Œ ê°€ì¤‘ì¹˜ ë³€ê²½
    correlation_fixed = np.zeros((10, 10))
    for i, w_imp in enumerate(weight_range):
        for j, w_beh in enumerate(weight_range):
            # Expert elementsëŠ” ê³ ì • ê°€ì¤‘ì¹˜ë¡œ ê³„ì‚°
            expert_scores_fixed = {}
            for exp in EXPERIMENT_NUMBERS:
                expert_elem = element_scores_expert.get(exp, {})
                if expert_elem:
                    # Calculate with fixed weights (5, 2, 1)
                    from evaluator import PSYCHE_RUBRIC
                    total = sum(
                        expert_elem.get(k, {}).get('score', 0) * (5 if PSYCHE_RUBRIC[k].get('type') == 'impulsivity' 
                                                                   else 2 if PSYCHE_RUBRIC[k].get('type') == 'behavior' 
                                                                   else 1)
                        for k in expert_elem.keys() if k in PSYCHE_RUBRIC
                    )
                    expert_scores_fixed[exp] = total
            
            # PSYCHE elementsëŠ” ë³€ê²½ëœ ê°€ì¤‘ì¹˜ë¡œ ê³„ì‚°
            psyche_scores_weighted = {}
            for exp in EXPERIMENT_NUMBERS:
                psyche_elem = element_scores_psyche.get(exp, {})
                if psyche_elem:
                    from evaluator import PSYCHE_RUBRIC
                    total = sum(
                        psyche_elem.get(k, {}).get('score', 0) * (w_imp if PSYCHE_RUBRIC[k].get('type') == 'impulsivity' 
                                                                   else w_beh if PSYCHE_RUBRIC[k].get('type') == 'behavior' 
                                                                   else 1)
                        for k in psyche_elem.keys() if k in PSYCHE_RUBRIC
                    )
                    psyche_scores_weighted[exp] = total
            
            # Correlation ê³„ì‚°
            x = [psyche_scores_weighted[exp] for exp in EXPERIMENT_NUMBERS if exp in psyche_scores_weighted and exp in expert_scores_fixed]
            y = [expert_scores_fixed[exp] for exp in EXPERIMENT_NUMBERS if exp in psyche_scores_weighted and exp in expert_scores_fixed]
            
            if len(x) >= 2:
                corr, _ = stats.pearsonr(x, y)
                correlation_fixed[9-i, j] = corr  # yì¶• ë°˜ì „
            else:
                correlation_fixed[9-i, j] = 0
    
    # Figure ìƒì„±
    fig, axes = plt.subplots(1, 2, figsize=(20, 8))
    
    # Heatmap 1
    ax1 = axes[0]
    im1 = ax1.imshow(correlation_equal, cmap='Greens', aspect='auto',
                     extent=[1, 10, 1, 10], origin='lower')
    cbar1 = plt.colorbar(im1, ax=ax1)
    cbar1.ax.set_ylabel('Correlation', fontsize=24, family='Helvetica')
    cbar1.ax.tick_params(labelsize=24)
    
    ax1.set_xlabel('$w_{Behavior}$', fontsize=32, family='Helvetica')
    ax1.set_ylabel('$w_{Impulsivity}$', fontsize=32, family='Helvetica')
    ax1.set_title('Equal weights', fontsize=32, family='Helvetica')
    ax1.set_xticks(range(1, 11))
    ax1.set_yticks(range(1, 11))
    ax1.tick_params(labelsize=22)
    ax1.grid(False)
    ax1.plot(2, 5, 'rs', markersize=10, label='(5, 2, 1)')
    
    for spine in ax1.spines.values():
        spine.set_color('black')
        spine.set_linewidth(1)
    
    # Heatmap 2
    ax2 = axes[1]
    im2 = ax2.imshow(correlation_fixed, cmap='Greens', aspect='auto',
                     extent=[1, 10, 1, 10], origin='lower')
    cbar2 = plt.colorbar(im2, ax=ax2)
    cbar2.ax.set_ylabel('Correlation', fontsize=24, family='Helvetica')
    cbar2.ax.tick_params(labelsize=24)
    
    ax2.set_xlabel('$w_{Behavior}$', fontsize=32, family='Helvetica')
    ax2.set_ylabel('$w_{Impulsivity}$', fontsize=32, family='Helvetica')
    ax2.set_title('Expert weights fixed at (5,2,1)', fontsize=32, family='Helvetica')
    ax2.set_xticks(range(1, 11))
    ax2.set_yticks(range(1, 11))
    ax2.tick_params(labelsize=22)
    ax2.grid(False)
    ax2.plot(2, 5, 'rs', markersize=10, label='(5, 2, 1)')
    
    for spine in ax2.spines.values():
        spine.set_color('black')
        spine.set_linewidth(1)
    
    plt.tight_layout()
    return fig

# ================================
# Figure 3: SP Validation Heatmap
# ================================
def load_sp_validation_data(root_data):
    """Load SP validation data for heatmap."""
    # SP validation ë°ì´í„° êµ¬ì¡°: sp_quantitative_{validator_name}_{client}_{page}
    # VALIDATION_ELEMENTS 24ê°œ
    
    SP_SEQUENCE = [
        (1, 6201), (2, 6202), (3, 6203), (4, 6204), (5, 6205), (6, 6206), (7, 6207),
        (8, 6203), (9, 6201), (10, 6204), (11, 6207), (12, 6202), (13, 6206), (14, 6205),
    ]
    
    VALIDATION_ELEMENTS = [
        "Chief complaint", "Symptom name", "Alleviating factor", "Exacerbating factor",
        "Triggering factor", "Stressor", "Diagnosis", "Substance use", "Current family structure",
        "Suicidal ideation", "Self mutilating behavior risk", "Homicide risk",
        "Suicidal plan", "Suicidal attempt", "Mood", "Verbal productivity", "Insight",
        "Affect", "Perception", "Thought process", "Thought content", "Spontaneity",
        "Social judgement", "Reliability"
    ]
    
    # Elementë³„ë¡œ í‰ê°€ìë“¤ì˜ "Appropriate" ë¹„ìœ¨ ê³„ì‚°
    element_conformity = {elem: [] for elem in VALIDATION_ELEMENTS}
    
    # ëª¨ë“  validator ë°ì´í„° ìˆ˜ì§‘
    validators_found = set()
    for key in (root_data or {}).keys():
        if key.startswith("sp_quantitative_"):
            parts = key.split("_")
            if len(parts) >= 4:
                validators_found.add(parts[2])  # validator name
    
    # ê° SP caseë³„ë¡œ ë°ì´í„° ìˆ˜ì§‘
    for page, client in SP_SEQUENCE:
        for validator in validators_found:
            key = f"sp_quantitative_{validator}_{client}_{page}"
            data = (root_data or {}).get(key, {})
            
            if 'quantitative_responses' in data:
                responses = data['quantitative_responses']
                for elem in VALIDATION_ELEMENTS:
                    if elem in responses:
                        value = responses[elem]
                        # "ì ì ˆí•¨" = 1, "ë¶€ì ì ˆí•¨" = 0
                        if value == "ì ì ˆí•¨":
                            element_conformity[elem].append(1)
                        elif value == "ë¶€ì ì ˆí•¨":
                            element_conformity[elem].append(0)
    
    # í‰ê·  ê³„ì‚° (%)
    conformity_percent = {}
    for elem, values in element_conformity.items():
        if values:
            conformity_percent[elem] = (sum(values) / len(values)) * 100
        else:
            conformity_percent[elem] = 0
    
    return conformity_percent

def create_sp_validation_heatmap(conformity_data):
    """Figure 3: Heatmap by elements (SP validation)."""
    if not conformity_data:
        return None
    
    # DataFrame ìƒì„± (elementë³„ë¡œ í•œ í–‰)
    elements = list(conformity_data.keys())
    conformities = list(conformity_data.values())
    
    df = pd.DataFrame({
        'Element': elements,
        'Conformity': conformities
    })
    
    # Transpose for vertical display
    df_pivot = df.set_index('Element').T
    
    # Figure ìƒì„±
    fig, ax = plt.subplots(figsize=(16, 6))
    
    # Heatmap
    sns.heatmap(df_pivot, cmap='Blues', vmin=0, vmax=100, 
                linewidths=0.5, cbar=True, annot=True, fmt='.0f',
                annot_kws={"fontsize": 10, "family": "Helvetica"},
                ax=ax, cbar_kws={'label': 'Conformity (%)'})
    
    # ì¶• ë¼ë²¨ ì„¤ì •
    plt.xticks(rotation=90, ha='center', fontsize=12, family='Helvetica')
    plt.yticks(rotation=0, fontsize=14, family='Helvetica')
    
    plt.title('Conformity Heatmap by Elements', fontsize=24, pad=20, family='Helvetica')
    
    # ì»¬ëŸ¬ë°” í°íŠ¸ ì„¤ì •
    cbar = ax.collections[0].colorbar
    cbar.ax.tick_params(labelsize=12)
    cbar.set_label('Conformity (%)', fontsize=14, family='Helvetica')
    
    plt.tight_layout()
    return fig

# ================================
# Download Helper
# ================================
def fig_to_bytes(fig, dpi=300):
    """Convert matplotlib figure to high-quality PNG bytes."""
    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=dpi, bbox_inches='tight')
    buf.seek(0)
    return buf.getvalue()

# ================================
# Main Application
# ================================
def main():
    plt.close('all')
    
    st.title("ğŸ“Š Publication Figure Generator")
    st.markdown("---")
    
    st.info("""
    **ë…¼ë¬¸ìš© Figure ìƒì„±**
    - ëª¨ë“  í°íŠ¸: Helvetica
    - ê³ í•´ìƒë„ PNG (300 DPI)
    - Figure 1: PSYCHE-Expert Correlation (3ê°€ì§€ ë²„ì „)
    - Figure 2: Weight-Correlation Analysis (2ê°œ heatmap)
    - Figure 3: SP Validation Heatmap
    """)
    
    # Load data
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        firebase_ref = get_firebase_ref()
        root_snapshot = firebase_ref.get() or {}
        expert_data = load_expert_scores(root_snapshot)
        psyche_scores = load_psyche_scores(root_snapshot)
        avg_expert_scores = calculate_average_expert_scores(expert_data)
        
        # Element-level scores for weight analysis
        element_scores_psyche = load_element_scores(root_snapshot)
        # Element-level scores for expert (from validation data)
        element_scores_expert = {}
        for validator in VALIDATORS:
            sanitized_name = sanitize_firebase_key(validator)
            for client_num, exp_num in EXPERIMENT_NUMBERS:
                key = f"expert_{sanitized_name}_{client_num}_{exp_num}"
                data = (root_snapshot or {}).get(key, {}) or {}
                if 'elements' in data:
                    if (client_num, exp_num) not in element_scores_expert:
                        element_scores_expert[(client_num, exp_num)] = {}
                    # ì²« ë²ˆì§¸ validator ë°ì´í„° ì‚¬ìš© (ë˜ëŠ” í‰ê·  ê³„ì‚° ê°€ëŠ¥)
                    if not element_scores_expert[(client_num, exp_num)]:
                        element_scores_expert[(client_num, exp_num)] = data['elements']
        
        # SP validation data
        sp_conformity_data = load_sp_validation_data(root_snapshot)
    
    st.success("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    
    # ================================
    # Figure 1: PSYCHE-Expert Correlation
    # ================================
    st.markdown("## ğŸ“ˆ Figure 1: PSYCHE-Expert Correlation")
    
    tab1, tab2, tab3 = st.tabs(["Average Expert", "Individual Validators", "By Disorder"])
    
    with tab1:
        st.markdown("### Figure 1-1: Average Expert Score")
        fig1_1 = create_correlation_plot_average(psyche_scores, avg_expert_scores)
        st.pyplot(fig1_1)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“¥ Download PNG (300 DPI)",
                data=fig_to_bytes(fig1_1),
                file_name="Fig1_1_PSYCHE_Expert_Correlation_Average.png",
                mime="image/png"
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ Download PNG (600 DPI)",
                data=fig_to_bytes(fig1_1, dpi=600),
                file_name="Fig1_1_PSYCHE_Expert_Correlation_Average_600dpi.png",
                mime="image/png"
            )
        plt.close(fig1_1)
    
    with tab2:
        st.markdown("### Figure 1-2: Individual Validators")
        fig1_2 = create_correlation_plot_by_validator(psyche_scores, expert_data)
        st.pyplot(fig1_2)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“¥ Download PNG (300 DPI)",
                data=fig_to_bytes(fig1_2),
                file_name="Fig1_2_PSYCHE_Expert_Correlation_Validators.png",
                mime="image/png"
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ Download PNG (600 DPI)",
                data=fig_to_bytes(fig1_2, dpi=600),
                file_name="Fig1_2_PSYCHE_Expert_Correlation_Validators_600dpi.png",
                mime="image/png"
            )
        plt.close(fig1_2)
    
    with tab3:
        st.markdown("### Figure 1-3: By Disorder")
        fig1_3 = create_correlation_plot_by_disorder(psyche_scores, avg_expert_scores)
        st.pyplot(fig1_3)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“¥ Download PNG (300 DPI)",
                data=fig_to_bytes(fig1_3),
                file_name="Fig1_3_PSYCHE_Expert_Correlation_Disorders.png",
                mime="image/png"
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ Download PNG (600 DPI)",
                data=fig_to_bytes(fig1_3, dpi=600),
                file_name="Fig1_3_PSYCHE_Expert_Correlation_Disorders_600dpi.png",
                mime="image/png"
            )
        plt.close(fig1_3)
    
    st.markdown("---")
    
    # ================================
    # Figure 2: Weight-Correlation Analysis
    # ================================
    st.markdown("## ğŸ”¥ Figure 2: Weight-Correlation Analysis")
    st.caption("ê°€ì¤‘ì¹˜ ë³€í™”ì— ë”°ë¥¸ correlation ë³€í™” ë¶„ì„")
    
    if element_scores_psyche and element_scores_expert:
        fig2 = create_weight_correlation_heatmaps(element_scores_psyche, element_scores_expert)
        st.pyplot(fig2)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“¥ Download PNG (300 DPI)",
                data=fig_to_bytes(fig2),
                file_name="Fig2_Weight_Correlation_Heatmaps.png",
                mime="image/png"
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ Download PNG (600 DPI)",
                data=fig_to_bytes(fig2, dpi=600),
                file_name="Fig2_Weight_Correlation_Heatmaps_600dpi.png",
                mime="image/png"
            )
        plt.close(fig2)
    else:
        st.warning("Element-level scores not available. Cannot generate weight correlation heatmaps.")
    
    st.markdown("---")
    
    # ================================
    # Figure 3: SP Validation Heatmap
    # ================================
    st.markdown("## ğŸ”µ Figure 3: SP Validation Heatmap")
    st.caption("Elementë³„ Conformity í‰ê· ")
    
    if sp_conformity_data:
        fig3 = create_sp_validation_heatmap(sp_conformity_data)
        if fig3:
            st.pyplot(fig3)
            
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="ğŸ“¥ Download PNG (300 DPI)",
                    data=fig_to_bytes(fig3),
                    file_name="Fig3_SP_Validation_Heatmap.png",
                    mime="image/png"
                )
            with col2:
                st.download_button(
                    label="ğŸ“¥ Download PNG (600 DPI)",
                    data=fig_to_bytes(fig3, dpi=600),
                    file_name="Fig3_SP_Validation_Heatmap_600dpi.png",
                    mime="image/png"
                )
            plt.close(fig3)
        else:
            st.warning("Failed to create SP validation heatmap.")
    else:
        st.info("SP validation ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 02_ê°€ìƒí™˜ìì—_ëŒ€í•œ_ì „ë¬¸ê°€_ê²€ì¦.pyì—ì„œ ê²€ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
